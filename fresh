#/bin/bash

function freshlog {
	echo "fresh log | $(date '+%Y-%m-%d %H:%M:%S') | $* "
}

## ANSI art :-)
function intro {
	echo " __                _"
	echo "/ _|              | |"
	echo "| |_ _ __ ___  ___| |___"
	echo "|  _| '__/ _ \/ __| '_  \ "
	echo "| | | | |  __/\__ \ | | |"
	echo "|_| |_|  \___||___/_| |_|"
	echo ""
}

intro

function exciting {
	echo ""
	echo "               _ _   _             "
	echo "              (_) | (_)            "
	echo "  _____  _____ _| |_ _ _ __   ____ "
	echo " / _ \ \/ / __| | __| | '_ \ / _  |"
	echo "|  __/>  < (__| | |_| | | | | (_| |"
	echo " \___/_/\_\___|_|\__|_|_| |_|\__, |"
	echo "                              __/ |"
	echo "                             |___/ "
	echo ""
	exit 0
}

function usage {

echo " _   _ ___  __ _  __ _  ___  "
echo "| | | / __|/ _\` |/ _\` |/ _ \ "
echo "| |_| \__ \ (_| | (_| |  __/ "
echo " \__,_|___/\__,_|\__, |\___| "
echo "                  __/ |      "
echo "                 |___/ "

	cat << EOF

Bash scripting to automate FreeSurfer usage
Use at your own risk, no warranty is provided
Flags explained
	-s <Subject>
	-d <Directory where subject data is located> (if not specified assumes current directory)
	-f <NII file to work on> (multiple instances of this flag possible)
	-l [Only the longitudinal pipelines are run, the recon-all -all are skipped]
	-r [Only the recon-all -all pipelines are run, the longitudinal are skipped]
	-n <number of processor cores to work with for parallel pipelines> (if not set defaults to slurm setting)
	-a <afni input file> (multiple instances of this flag possible)
	-x [Dry Run mode]
	-h [Print this help message]

EOF

exciting

}

function sane {
	if [ "$dryrunflag" == "YES" ]; then # dry run or not
		freshlog "Dry run called - Not Doing - $@"
	else
		freshlog "Doing - $*"
		"$@"
	fi
	local status=$?
	if [ $status -ne 0 ]; then
		freshlog "**** ERROR WITH: $1" >&2
		freshlog "Exiting because of the previous error"
		exit 101
	fi
	#return $status
	freshlog "Done"
}

function env_setup {

	. /etc/profile.d/modules.sh
	module purge
	module load tcin apps fresh

	if [ "$1" = "stable" ]; then
			freshlog "Loading stable FreeSurfer module"
			module load freesurfer/6.0
	elif [ "$1" == "dev" ]; then
		freshlog "Loading development FreeSurfer module"
		module load freesurfer/6-dev-20180918
		export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=$cores
	elif [ "$1" == "afni" ]; then
		freshlog "Loading AFNI module"
		module load afni/17.1.03
	fi

	freshlog "Loaded module(s) are:"
	module list

}

## Pre-Processing Functions ##

function pp1 { # stage 1 pre-processing, mri_convert & recon-all -i (T1 files only)
	local myfile="$1"
	local mysubject="$2"
	local mywave="$3"
	freshlog "Stage 1 pre-processing of $myfile"
	env_setup stable
	# mri_conver re-sampling steps
	local rsfilename="$(echo $myfile | sed -e 's/\(.nii.gz\)*$//g')""_RS.nii.gz" # file name with _RS inserted for re-sampled files
	if [ -e "$rsfilename" ]; then # re-sampled file already exists, no need for re-sampling
		freshlog "$rsfilename already exists, not re-sampling it"
	else
		sane mri_convert -cs 0.9 "$myfile" "$rsfilename"
	fi
	# recon-all -i
	if [ ! -d "$mysubject""_""$mywave" ]; then # check to make sure the resulting directory doesn't already exist, this step will have been done if it did
		sane recon-all -i "$rsfilename" -s "$mysubject""_""$mywave"
	fi
}

function pp2 { # stage 2 pre-processing, recon-all -all
	local myfile="$1"
	local mysubject="$2"
	local mywave="$3"
	local myfiletype="$4"
	freshlog "Stage 2 pre-processing of $myfile"
	# T1
	if [ "$myfiletype" == "T1" ]; then
		local myt2comparator="$mysubject"_"$mywave"_T2_GR_FP.nii.gz"" #s5519_w1_T2_GR_FP.nii.gz
		if [ ! -e "$myt2comparator" ]; then # if there are T2 files for this sample the T1 pre-processing is redundant
			sane recon-all -all -3T -parallel -openmp "$cores" -s "$mysubject""_""$mywave" -hippocampal-subfields-T1
		else
			freshlog "T2 comparator $myt2comparator for $myfile exists, hence, T1 pre-processing is redundant"
		fi
	fi
	# T2
	##FIXME - something going wrong here
	if [ "$myfiletype" == "T2" ]; then
		if [ -d "$mysubject""_""$wave" ]; then # "$subject""_""$wave" exists, ergo -T1 -all, (a requirement), should have run
			t2imageloc="$mysubject""_""$mywave""_T2_GR_FP.nii.gz"
			sane recon-all -all -3T -cm -parallel -openmp "$cores" -T2 "$t2imageloc" -T2pial -s "$mysubject""_""$mywave" -hippocampal-subfields-T1T2 "$t2imageloc" T1andT2_based
		else
			freshlog "Not Doing - (doesn't "$subject""_""$wave" exist) - recon-all -all -3T -cm -parallel -openmp "$cores" -T2 "$t2imageloc" -T2pial -s "$mysubject""_""$mywave" -hippocampal-subfields-T1T2 "$t2imageloc" T1andT2_based"
			freshlog "The required "$subject""_""$wave" directory for the T2 step doesn't exist"
			freshlog "adding $myfile to backlog array for later processing"
			backlog=("${backlog[@]}" "$myfile")
			freshlog "content of the backlog array"
			echo "${backlog[@]}"
		fi
	fi
}

function afni_pre_processing {

## AFNI sanity checks

	env_setup afni

	## FIXME - way to pass specific AFNI flags
	for afni_input in "${afni_inputs[@]}"
	do
		local afni_output="$afni_input""_RS"
		sane 3dresample -orient ras -dxyz 1.2 1.1 1.1 -prefix "$afni_output" -input "$afni_input"
	done

	# *3dresample* -*orient* ras *-dxyz* 1.2 1.1 1.1 *-prefix* <output_name> *-input* <input_name>
	# (those in bold are part of the command, those in normal are the
	# parameters people can change according to their data)

}

function pp3 { # segment*.sh steps
	env_setup dev
	freshlog "Stage 3 Pre-processing steps"
	mysubject="$1"
	mywave="$2"
	sane segmentHA_T1.sh "$mysubject""_""$mywave"
	sane segmentBS.sh "$mysubject""_""$mywave"
	sane segmentThalamicNuclei.sh "$mysubject""_""$mywave"

	#for wave in "${waves[@]}"; do
	t2imageloc="$mysubject""_""$wave""_T2_GR_FP.nii.gz"
	if [ -e "$t2imageloc" ]; then # T2 images present, they need another step
		sane segmentHA_T2.sh "$mysubject""_""$wave" $directory/"$mysubject""_""$wave""_T2_GR_FP.nii.gz" T1andT2_based 1
	fi
	#done

	freshlog "recon-all steps completed"
	freshlog "# ----------------------- #"

}

function do_longitudianal {

	freshlog "# ------------------------ #"
	freshlog "Starting Longitudianal Pipeline"

	## sanity check to make sure we have a subject id
	if [ -z "$subject" ]; then
		freshlog "No subject ID available, exiting without going further"
		freshlog "the subject id can be specified with the -s flag if needed"
		exciting
	fi

	freshlog "Detected there are ${#uniqwaves[@]} time points"

	env_setup stable

	## recon-all -base has the following format
	## recon-all -base "$subject""base" -tp $subject_$timepoint1 -tp $subject_timepoint2 -tp $subject_timepoint3 -all
	## thus we need to build an array of the waves and pass them to it
	for wave in "${uniqwaves[@]}"
	do
		local timepointrefs=("${timepointrefs[@]}" "-tp" "$subject""_""$wave")
	done

	sane recon-all -base "$subject""base" "${timepointrefs[@]}" -all

	lastwave=$(echo "${uniqwaves[*]}" | sort -nr | awk '{print $NF}')
	freshlog "Determining the last time series to be $lastwave"
		## `--> thought this step only ran on last time point but it runs on all
		##			keeping the variable incase it comes in useful elsewhere

	for wave in "${uniqwaves[@]}"
	do
		sane recon-all -long "$subject""_""$wave" "$subject""base" -all
	done

	env_setup dev

	freshlog "Starting segmentHA_T1_long.sh step"
	sane segmentHA_T1_long.sh "$subject"base

	freshlog "Starting segmentBS.sh steps"

	for wave in "${uniqwaves[@]}"
	do
		sane segmentBS.sh "$subject""_""$wave".long."$subject"base
	done

	freshlog "Finished segmentBS.sh steps"

	freshlog "Starting segmentThalamicNuclei.sh steps"

	for wave in "${uniqwaves[@]}"
	do
		sane segmentThalamicNuclei.sh "$subject""_""$wave".long."$subject"base
	done

	freshlog "Finished longitudianal steps"
	freshlog "# ------------------------ #"
}

# get the flags
while getopts "s:d:f:a:n:rlx" OPTION
do
	case $OPTION in
		s)
			subject=$OPTARG
			;;
		d)
			directory=$OPTARG
			;;
		f)
			files=(${files[@]} "$OPTARG")
			;;
		r)
			recononly="YES"
			;;
		l)
			longonly="YES"
			;;
		x)
			dryrunflag="YES"
			;;
		a)
			afni_inputs=(${afni_inputs[@]} "$OPTARG")
			;;
		n)
			cores=$OPTARG
			;;
		?)
			usage
			exit
			;;
	esac
done

## Sanity Checks
for file in "${files[@]}"; do
	if [ ! -f "$file" ]; then
		freshlog "Can't find the file $file referenced with the -f flag"
		usage
		freshlog "Exiting without going furhter"
		exit 90
	else
		freshlog "Will be working on file: $file"
	fi
done

for afni_file in "${afni_inputs[@]}"
do
        if [ ! -f "$afni_file" ]; then
                freshlog "Can't find the AFNI file $afni_file referenced with the -a flag"
                usage
                freshlog "Exiting without going further"
                exit 90
        else
                freshlog "Will be using AFNI Pre-Processing on file: $afni_file"
        fi
done


if [ -z "$directory" ]; then
	directory=$(pwd)
fi
export SUBJECTS_DIR=$directory
freshlog "Setting directory to be $directory"
freshlog "Setting SUBJECTS_DIR = $directory"

## if not specified assuming the number of cores is being dictated by a slurm allocation
if [ -z "$cores" ]; then
	cores="$SLURM_TASKS_PER_NODE"
fi
freshlog "Number of Cores to work with = $cores"

for file in "${files[@]}"
do
	if [ ! -f "$file" ]; then
		freshlog "Can't find the file $file referenced with the -f flag"
		usage
		freshlog "Exiting without going furhter"
		exit 90
	fi
done

## =================== ##
## Worflow starts here ##
## =================== ##

freshlog "# Pipelines Starting #"

freshlog "Preprocessing steps"
freshlog "==================="

#if [ "$longonly" != "YES" ]; then
for file in "${files[@]}"; do
	# this is very brittle
	subject="${file:0:5}"
	wave="${file:6:2}"
	# pop these waves into a waves array for later use.
	waves=("${waves[@]}" "$wave")
	filetype="${file:9:2}"
	freshlog "Paramaters: file = $file subject = $subject wave = $wave filetype = $filetype"

	if [ "$longonly" == "YES" ]; then # longonly var set, ergo don't do this step
		freshlog "** skipping reconall -all steps **"
		freshlog "fresh has been run with the -l flag, which means run the Longitudinal processing only"
	else
		freshlog "Will be working on file: $file"
		if [ "$filetype" == "T1" ]; then
			freshlog "Preprocessing $file"
			pp1 "$file" "$subject" "$wave"
			pp2 "$file" "$subject" "$wave" "T1"
		else
			freshlog "$file determined to be a T2 file which does not need stage 1 pre-processing, just stage 2"
			pp2 "$file" "$subject" "$wave" "T2"
		fi
	fi

	freshlog "In case there were T2 files that where skipped because their"
	freshlog "corresponding subjectID_wave directory from the recon-all -i"
	freshlog "step of their T1 files hadn't been created already. Those T2"
	freshlog "files get added to another array. Iterate through it."
	for file in "${backlog[@]}"; do
		if [ "$longonly" != "YES" ]; then
			pp2 $file
		fi
	done

done

# waves array may have duplicates from the above
freshlog "removing duplicates from waves array"
freshlog "contents of waves array BEFORE removal of duplicates:"
echo ${waves[@]}
uniqwaves=($(echo "${waves[@]}" | tr ' ' '\n' | sort -u | tr '\n' ' '))
freshlog "contents of waves array AFTER removal of duplicates:"
echo ${uniqwaves[@]}

freshlog "stage 3 pre-processing, segment*.sh"
for wave in "${uniqwaves[@]}"; do
	if [ "$longonly" != "YES" ]; then
		pp3 "$subject" "$wave"
		# this defaults the subject id to whatever it was last set at, may be an issue!?
	fi
done

freshlog "Preprocessing steps finished"
freshlog "============================"
freshlog ""

if [ "$recononly" == "YES" ]; then 
	freshlog "-r flag passed - stop now as should only do reconall -all steps, not the longitidinal"
	exciting
fi

#fi # close "$longonly" != "YES" conditional

freshlog "Longitudinal processing"

do_longitudianal


exciting

exit 0
